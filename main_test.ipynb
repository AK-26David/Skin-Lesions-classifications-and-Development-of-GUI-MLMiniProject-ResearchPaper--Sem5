{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Features ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(image):\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute the GLCM (Gray Level Co-occurrence Matrix)\n",
    "    glcm = greycomatrix(gray_image, distances=[1], angles=[0], symmetric=True, normed=True)\n",
    "    \n",
    "    # Extract texture properties: Contrast, Correlation, Energy, and Homogeneity\n",
    "    contrast = greycoprops(glcm, 'contrast')[0, 0]\n",
    "    correlation = greycoprops(glcm, 'correlation')[0, 0]\n",
    "    energy = greycoprops(glcm, 'energy')[0, 0]\n",
    "    homogeneity = greycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    \n",
    "    return [contrast, correlation, energy, homogeneity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image):\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute HOG features\n",
    "    hog_features, hog_image = hog(gray_image, \n",
    "                                  pixels_per_cell=(16, 16), \n",
    "                                  cells_per_block=(2, 2), \n",
    "                                  block_norm='L2-Hys', \n",
    "                                  visualize=True, \n",
    "                                  multichannel=False)\n",
    "    \n",
    "    return hog_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Loop through subfolders, where each folder represents a class (e.g., Benign or Malignant)\n",
    "    for label_folder in os.listdir(folder):\n",
    "        label_path = os.path.join(folder, label_folder)\n",
    "        if os.path.isdir(label_path):\n",
    "            for filename in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, filename)\n",
    "                img = cv2.imread(img_path)  # Read the image\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(label_folder)  # The folder name becomes the class label\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_images):\n",
    "    X_features = []\n",
    "    \n",
    "    for img in X_images:\n",
    "        # Extract GLCM (texture) features\n",
    "        glcm_features = extract_glcm_features(img)\n",
    "        \n",
    "        # Extract HOG (shape) features\n",
    "        hog_features = extract_hog_features(img)\n",
    "        \n",
    "        # Combine both sets of features\n",
    "        combined_features = np.concatenate((glcm_features, hog_features))\n",
    "        \n",
    "        # Add the combined features to the feature list\n",
    "        X_features.append(combined_features)\n",
    "        \n",
    "    return np.array(X_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X_features \u001b[38;5;241m=\u001b[39m prepare_data(X_images)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Split dataset into training and test sets (80% train, 20% test)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Scale the feature data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "File \u001b[0;32m~/Documents/Skin-Lesions-classifications-and-Development-of-GUI/.venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Skin-Lesions-classifications-and-Development-of-GUI/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2785\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Skin-Lesions-classifications-and-Development-of-GUI/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2415\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2412\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2419\u001b[0m     )\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Load dataset (assuming images are stored in 'data' folder)\n",
    "X_images, y_labels = load_images_from_folder('ISIC-images')\n",
    "\n",
    "# Prepare feature set by extracting features from the images\n",
    "X_features = prepare_data(X_images)\n",
    "\n",
    "# Split dataset into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@400.466] global loadsave.cpp:241 findDecoder imread_('path_to_your_image.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 116\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m    115\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_your_image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 116\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_lesion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features from the image.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 104\u001b[0m, in \u001b[0;36manalyze_lesion\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_lesion\u001b[39m(image_path):\n\u001b[0;32m--> 104\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     color_features \u001b[38;5;241m=\u001b[39m extract_color_features(img)\n\u001b[1;32m    107\u001b[0m     texture_features \u001b[38;5;241m=\u001b[39m extract_texture_features(img)\n",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path, target_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m300\u001b[39m)):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m---> 10\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Resize\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, target_size)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy.stats import skew\n",
    "\n",
    "def preprocess_image(image_path, target_size=(300, 300)):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Extract the circular region of interest\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, (img.shape[1]//2, img.shape[0]//2), min(img.shape[0], img.shape[1])//2 - 10, (255), -1)\n",
    "    img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    enhanced_lab = cv2.merge((cl,a,b))\n",
    "    img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    # Normalize\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "def extract_color_features(img):\n",
    "    features = []\n",
    "    \n",
    "    # Color moments (mean, std, skewness) for each channel\n",
    "    for i in range(3):\n",
    "        channel = img[:,:,i]\n",
    "        features.extend([channel[channel != 0].mean(), channel[channel != 0].std(), skew(channel[channel != 0].ravel())])\n",
    "    \n",
    "    # Color histograms\n",
    "    for i in range(3):\n",
    "        hist = cv2.calcHist([img], [i], None, [32], [0, 1])\n",
    "        features.extend(hist.flatten())\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_texture_features(img):\n",
    "    features = []\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Local Binary Patterns\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    features.extend(hist)\n",
    "    \n",
    "    # Haralick texture features\n",
    "    glcm = graycomatrix(gray, [5], [0], 256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "    for prop in props:\n",
    "        features.extend(graycoprops(glcm, prop).flatten())\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_shape_features(img):\n",
    "    features = []\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Area and Perimeter\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        features.extend([area, perimeter])\n",
    "        \n",
    "        # Circularity\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "        features.append(circularity)\n",
    "        \n",
    "        # Asymmetry\n",
    "        (x, y), (MA, ma), angle = cv2.fitEllipse(cnt)\n",
    "        asymmetry = MA / ma\n",
    "        features.append(asymmetry)\n",
    "        \n",
    "        # Border irregularity\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = float(area) / hull_area\n",
    "        features.append(solidity)\n",
    "    else:\n",
    "        features.extend([0] * 5)  # Placeholder if no contour found\n",
    "    \n",
    "    return features\n",
    "\n",
    "def analyze_lesion(image_path):\n",
    "    img = preprocess_image(image_path)\n",
    "    \n",
    "    color_features = extract_color_features(img)\n",
    "    texture_features = extract_texture_features(img)\n",
    "    shape_features = extract_shape_features(img)\n",
    "    \n",
    "    all_features = np.concatenate([color_features, texture_features, shape_features])\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "# Usage\n",
    "image_path = \"path_to_your_image.jpg\"\n",
    "features = analyze_lesion(image_path)\n",
    "print(f\"Extracted {len(features)} features from the image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 25431/25431 [1:22:39<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25431 images. Results saved to 'skin_lesion_features.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy.stats import skew\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_image(img, target_size=(300, 300)):\n",
    "    # Resize\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Extract the circular region of interest\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, (img.shape[1]//2, img.shape[0]//2), min(img.shape[0], img.shape[1])//2 - 10, (255), -1)\n",
    "    img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    enhanced_lab = cv2.merge((cl,a,b))\n",
    "    img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    # Normalize\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "def extract_color_features(img):\n",
    "    features = []\n",
    "    \n",
    "    # Color moments (mean, std, skewness) for each channel\n",
    "    for i in range(3):\n",
    "        channel = img[:,:,i]\n",
    "        features.extend([channel[channel != 0].mean(), channel[channel != 0].std(), skew(channel[channel != 0].ravel())])\n",
    "    \n",
    "    # Color histograms\n",
    "    for i in range(3):\n",
    "        hist = cv2.calcHist([img], [i], None, [32], [0, 1])\n",
    "        features.extend(hist.flatten())\n",
    "    \n",
    "    return features\n",
    "\n",
    "def gabor_features(img, frequencies=[0.1, 0.2, 0.3], orientations=[0, 45, 90, 135]):\n",
    "    features = []\n",
    "    for theta in orientations:\n",
    "        for frequency in frequencies:\n",
    "            # Create Gabor filter\n",
    "            kernel = cv2.getGaborKernel((21, 21), 8.0, np.radians(theta), frequency, 0.5, 0, ktype=cv2.CV_32F)\n",
    "            filtered = cv2.filter2D(img, cv2.CV_8UC3, kernel)\n",
    "\n",
    "            # Calculate mean and standard deviation of the filtered image\n",
    "            features.append(filtered.mean())\n",
    "            features.append(filtered.std())\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_texture_features(img):\n",
    "    features = []\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Local Binary Patterns\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    features.extend(hist)\n",
    "    \n",
    "    # Haralick texture features\n",
    "    glcm = graycomatrix(gray, [5], [0], 256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "    for prop in props:\n",
    "        features.extend(graycoprops(glcm, prop).flatten())\n",
    "    \n",
    "    # Gabor filter features\n",
    "    features.extend(gabor_features(gray))  # Add Gabor features\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_shape_features(img):\n",
    "    features = []\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Area and Perimeter\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        features.extend([area, perimeter])\n",
    "        \n",
    "        # Circularity\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "        features.append(circularity)\n",
    "        \n",
    "        # Asymmetry\n",
    "        (x, y), (MA, ma), angle = cv2.fitEllipse(cnt)\n",
    "        asymmetry = MA / ma\n",
    "        features.append(asymmetry)\n",
    "        \n",
    "        # Border irregularity\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = float(area) / hull_area\n",
    "        features.append(solidity)\n",
    "    else:\n",
    "        features.extend([0] * 5)  # Placeholder if no contour found\n",
    "    \n",
    "    return features\n",
    "\n",
    "def analyze_lesion(img):\n",
    "    img = preprocess_image(img)\n",
    "    \n",
    "    color_features = extract_color_features(img)\n",
    "    texture_features = extract_texture_features(img)\n",
    "    shape_features = extract_shape_features(img)\n",
    "    \n",
    "    all_features = np.concatenate([color_features, texture_features, shape_features])\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "def process_image_folder(folder_path):\n",
    "    all_features = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        features = analyze_lesion(img)\n",
    "        all_features.append(features)\n",
    "        image_names.append(image_file)\n",
    "    \n",
    "    # Create a DataFrame with the features\n",
    "    feature_names = [f'feature_{i}' for i in range(len(all_features[0]))]\n",
    "    df = pd.DataFrame(all_features, columns=feature_names)\n",
    "    df['image_name'] = image_names\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "folder_path = \"ISIC-images\"\n",
    "results_df = process_image_folder(folder_path)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(\"skin_lesion_features.csv\", index=False)\n",
    "print(f\"Processed {len(results_df)} images. Results saved to 'skin_lesion_features.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 100/100 [00:18<00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 images. Results saved to 'skin_lesion_features.csv'\n",
      "Total number of features: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy.stats import skew\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_image(img, target_size=(300, 300)):\n",
    "    # Resize\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Extract the circular region of interest\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, (img.shape[1]//2, img.shape[0]//2), min(img.shape[0], img.shape[1])//2 - 10, (255), -1)\n",
    "    img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    enhanced_lab = cv2.merge((cl,a,b))\n",
    "    img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    # Normalize\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "def extract_color_features(img):\n",
    "    features = {}\n",
    "    channels = ['R', 'G', 'B']\n",
    "    \n",
    "    # Color moments (mean, std, skewness) for each channel\n",
    "    for i, channel in enumerate(channels):\n",
    "        channel_data = img[:,:,i]\n",
    "        features[f'color_mean_{channel}'] = channel_data[channel_data != 0].mean()\n",
    "        features[f'color_std_{channel}'] = channel_data[channel_data != 0].std()\n",
    "        features[f'color_skew_{channel}'] = skew(channel_data[channel_data != 0].ravel())\n",
    "    \n",
    "    # Color histograms\n",
    "    for i, channel in enumerate(channels):\n",
    "        hist = cv2.calcHist([img], [i], None, [32], [0, 1])\n",
    "        for j, value in enumerate(hist.flatten()):\n",
    "            features[f'color_hist_{channel}_{j}'] = value\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_texture_features(img):\n",
    "    features = {}\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Local Binary Patterns\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    for i, value in enumerate(hist):\n",
    "        features[f'lbp_{i}'] = value\n",
    "    \n",
    "    # Haralick texture features\n",
    "    glcm = graycomatrix(gray, [5], [0], 256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "    for prop in props:\n",
    "        value = graycoprops(glcm, prop)[0, 0]\n",
    "        features[f'haralick_{prop}'] = value\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_shape_features(img):\n",
    "    features = {}\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Area and Perimeter\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        features['shape_area'] = area\n",
    "        features['shape_perimeter'] = perimeter\n",
    "        \n",
    "        # Circularity\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "        features['shape_circularity'] = circularity\n",
    "        \n",
    "        # Asymmetry\n",
    "        (x, y), (MA, ma), angle = cv2.fitEllipse(cnt)\n",
    "        asymmetry = MA / ma\n",
    "        features['shape_asymmetry'] = asymmetry\n",
    "        \n",
    "        # Border irregularity\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = float(area) / hull_area\n",
    "        features['shape_border_irregularity'] = solidity\n",
    "    else:\n",
    "        for feature in ['shape_area', 'shape_perimeter', 'shape_circularity', 'shape_asymmetry', 'shape_border_irregularity']:\n",
    "            features[feature] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "def analyze_lesion(img):\n",
    "    img = preprocess_image(img)\n",
    "    \n",
    "    features = {}\n",
    "    features.update(extract_color_features(img))\n",
    "    features.update(extract_texture_features(img))\n",
    "    features.update(extract_shape_features(img))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def process_image_folder(folder_path):\n",
    "    all_features = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        features = analyze_lesion(img)\n",
    "        all_features.append(features)\n",
    "        image_names.append(image_file)\n",
    "    \n",
    "    # Create a DataFrame with the features\n",
    "    df = pd.DataFrame(all_features)\n",
    "    df['image_name'] = image_names\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "folder_path = \"ISIC-images\"\n",
    "results_df = process_image_folder(folder_path)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(\"skin_lesion_features.csv\", index=False)\n",
    "print(f\"Processed {len(results_df)} images. Results saved to 'skin_lesion_features.csv'\")\n",
    "print(f\"Total number of features: {len(results_df.columns) - 1}\")  # -1 for the image_name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Load the newly generated data after improving feature extraction\n",
    "df = pd.read_csv(\"skin_lesion_features.csv\")\n",
    "\n",
    "# Step 2: Assume we have a target variable called 'label'\n",
    "# You should replace this with the actual labels after loading the proper dataset\n",
    "df['label'] = np.random.choice(['benign', 'malignant'], size=len(df))\n",
    "\n",
    "# Step 3: Separate features and target\n",
    "X = df.drop(['image_name', 'label'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Step 4: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 6: SVM Model - Perform Grid Search for hyperparameter tuning\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'poly', 'linear'],  # Added 'linear' kernel for feature importance\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}\n",
    "\n",
    "svm_grid = GridSearchCV(SVC(random_state=42), svm_param_grid, cv=5, n_jobs=-1)\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 7: Evaluate SVM Model\n",
    "print(\"SVM Best Parameters:\", svm_grid.best_params_)\n",
    "print(\"SVM Best Score:\", svm_grid.best_score_)\n",
    "\n",
    "svm_pred = svm_grid.predict(X_test_scaled)\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_pred))\n",
    "\n",
    "# Step 8: MLP Model - Perform Grid Search for hyperparameter tuning\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "mlp_grid = GridSearchCV(MLPClassifier(random_state=42, max_iter=1000), mlp_param_grid, cv=5, n_jobs=-1)\n",
    "mlp_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 9: Evaluate MLP Model\n",
    "print(\"\\nMLP Best Parameters:\", mlp_grid.best_params_)\n",
    "print(\"MLP Best Score:\", mlp_grid.best_score_)\n",
    "\n",
    "mlp_pred = mlp_grid.predict(X_test_scaled)\n",
    "print(\"\\nMLP Classification Report:\")\n",
    "print(classification_report(y_test, mlp_pred))\n",
    "\n",
    "# Step 10: Plot Confusion Matrices for both SVM and MLP\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, svm_pred, \"SVM Confusion Matrix\")\n",
    "plot_confusion_matrix(y_test, mlp_pred, \"MLP Confusion Matrix\")\n",
    "\n",
    "# Step 11: Feature Importance (for SVM with linear kernel)\n",
    "if svm_grid.best_estimator_.kernel == 'linear':\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': abs(svm_grid.best_estimator_.coef_[0])\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importance.head(20))\n",
    "    plt.title('Top 20 Important Features (SVM)')\n",
    "    plt.show()\n",
    "\n",
    "# Step 12: Predictions on New Data\n",
    "new_data = X_test_scaled[:5]  # Example: First 5 samples of the test set\n",
    "svm_new_pred = svm_grid.predict(new_data)\n",
    "mlp_new_pred = mlp_grid.predict(new_data)\n",
    "\n",
    "print(\"\\nSVM Predictions on new data:\", svm_new_pred)\n",
    "print(\"MLP Predictions on new data:\", mlp_new_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nikhil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading malignant images:   0%|          | 0/1197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading malignant images: 100%|██████████| 1197/1197 [00:11<00:00, 103.28it/s]\n",
      "Loading benign images: 100%|██████████| 1440/1440 [00:14<00:00, 96.62it/s] \n",
      "Loading malignant images: 100%|██████████| 300/300 [00:04<00:00, 66.45it/s]\n",
      "Loading benign images: 100%|██████████| 360/360 [00:04<00:00, 86.48it/s] \n",
      "Processing images: 100%|██████████| 2637/2637 [03:13<00:00, 13.66it/s]\n",
      "Processing images: 100%|██████████| 660/660 [00:47<00:00, 14.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import shannon_entropy\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage import feature\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "\n",
    "def load_dataset(folder_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for label in ['malignant', 'benign']:\n",
    "        folder = os.path.join(folder_path, label)\n",
    "        for img_name in tqdm(os.listdir(folder), desc=f\"Loading {label} images\"):\n",
    "            img_path = os.path.join(folder, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                if len(img.shape) == 2:  # Grayscale image (2D)\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)  # Convert grayscale to RGB\n",
    "                else:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB from BGR\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "# Load train and test sets\n",
    "train_data, train_labels = load_dataset(\"train\")\n",
    "test_data, test_labels = load_dataset(\"test\")\n",
    "\n",
    "# Convert labels to binary format (0 for benign, 1 for malignant)\n",
    "train_labels = np.where(train_labels == 'benign', 0, 1)\n",
    "test_labels = np.where(test_labels == 'benign', 0, 1)\n",
    "\n",
    "def extract_shape_features(img):\n",
    "    features = []\n",
    "\n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2) if perimeter != 0 else 0\n",
    "        features.extend([area, perimeter, circularity])\n",
    "\n",
    "        if len(cnt) >= 5:\n",
    "            (x, y), (MA, ma), angle = cv2.fitEllipse(cnt)\n",
    "            asymmetry = MA / ma if ma != 0 else 0\n",
    "            features.append(asymmetry)\n",
    "        else:\n",
    "            features.append(0)\n",
    "\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = float(area) / hull_area if hull_area != 0 else 0\n",
    "        features.append(solidity)\n",
    "    else:\n",
    "        features.extend([0] * 5)\n",
    "\n",
    "    return np.array(features).ravel()\n",
    "\n",
    "def extract_texture_features(img):\n",
    "    features = []\n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    features.extend(hist)\n",
    "\n",
    "    glcm = graycomatrix(gray, [5], [0], 256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "    for prop in props:\n",
    "        value = graycoprops(glcm, prop)[0, 0]\n",
    "        features.append(value)\n",
    "\n",
    "    return np.array(features).ravel()\n",
    "\n",
    "def extract_color_features(img):\n",
    "    features = []\n",
    "    for i in range(3):\n",
    "        channel = img[:,:,i]\n",
    "        non_zero_pixels = channel[channel != 0]\n",
    "        if non_zero_pixels.size > 0:\n",
    "            mean, std_dev, skewness = non_zero_pixels.mean(), non_zero_pixels.std(), skew(non_zero_pixels.ravel())\n",
    "            features.extend([mean, std_dev, skewness])\n",
    "        else:\n",
    "            features.extend([0, 0, 0])\n",
    "\n",
    "        hist = cv2.calcHist([img], [i], None, [32], [0, 1])\n",
    "        features.extend(hist.flatten())\n",
    "\n",
    "    return np.array(features).ravel()\n",
    "\n",
    "# Define Gabor filter function\n",
    "def extract_gabor_features(img, num_kernels=8):\n",
    "    gabor_features = []\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    ksize = 31  # Kernel size\n",
    "\n",
    "    for theta in np.arange(0, np.pi, np.pi / num_kernels):\n",
    "        kernel = cv2.getGaborKernel((ksize, ksize), sigma=4.0, theta=theta, lambd=10.0, gamma=0.5, psi=0)\n",
    "        filtered_img = cv2.filter2D(img_gray, cv2.CV_8UC3, kernel)\n",
    "        mean, std_dev = cv2.meanStdDev(filtered_img)\n",
    "        gabor_features.extend([mean[0][0], std_dev[0][0]])\n",
    "\n",
    "    return gabor_features\n",
    "\n",
    "# Define HOG function\n",
    "def extract_hog_features(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hog_features, _ = hog(img_gray, orientations=8, pixels_per_cell=(16, 16),\n",
    "                          cells_per_block=(1, 1), block_norm='L2-Hys', visualize=True)\n",
    "    return hog_features\n",
    "\n",
    "# Existing functions for color, texture, and shape features remain unchanged...\n",
    "\n",
    "def preprocess_image(img):\n",
    "    if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray_img = img\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_img = clahe.apply(gray_img)\n",
    "    return clahe_img\n",
    "\n",
    "def analyze_lesion(img):\n",
    "    # Ensure the image is in RGB\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    color_features = extract_color_features(img)\n",
    "    texture_features = extract_texture_features(img)\n",
    "    shape_features = extract_shape_features(img)\n",
    "    gabor_features = extract_gabor_features(img)\n",
    "    hog_features = extract_hog_features(img)\n",
    "\n",
    "    return np.concatenate([color_features, texture_features, shape_features, gabor_features, hog_features])\n",
    "\n",
    "def process_dataset(data, labels):\n",
    "    features = []\n",
    "    for img in tqdm(data, desc=\"Processing images\"):\n",
    "        processed_img = preprocess_image(img)\n",
    "        img_features = analyze_lesion(processed_img)\n",
    "        features.append(img_features)\n",
    "    \n",
    "    features = np.array(features)\n",
    "    return features, labels\n",
    "\n",
    "# Process train and test sets\n",
    "X_train_raw, y_train = process_dataset(train_data, train_labels)\n",
    "X_test_raw, y_test = process_dataset(test_data, test_labels)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=50)  # Adjust n_components to retain desired variance\n",
    "X_train = pca.fit_transform(X_train_raw)\n",
    "X_test = pca.transform(X_test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVM Best Score: 0.7808133517336554\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83       360\n",
      "           1       0.79      0.82      0.81       300\n",
      "\n",
      "    accuracy                           0.82       660\n",
      "   macro avg       0.82      0.82      0.82       660\n",
      "weighted avg       0.82      0.82      0.82       660\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Best Parameters: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant'}\n",
      "MLP Best Score: 0.7770154102696797\n",
      "\n",
      "MLP Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       360\n",
      "           1       0.77      0.79      0.78       300\n",
      "\n",
      "    accuracy                           0.80       660\n",
      "   macro avg       0.80      0.80      0.80       660\n",
      "weighted avg       0.80      0.80      0.80       660\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAIjCAYAAAAk+FJEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvoUlEQVR4nO3dd5RV5f3/7feAMCCdgGIFS8ReY4wVUOxiIYrG+A3YEo2xYTcxokaxdyMmFtAEYyfGFruIsUes0diwRFHAKEiXOb8/fJwnE0AHHJg7el1rsZZz7332+exxLXy5Z589VZVKpRIAAChQk8YeAAAA5kasAgBQLLEKAECxxCoAAMUSqwAAFEusAgBQLLEKAECxxCoAAMUSqwAAFEusAiwEr776arbaaqu0a9cuVVVVGTFiRIMef8yYMamqqsrQoUMb9Lj/y3r27JmePXs29hjA1yRWgQYxdOjQVFVVpaqqKqNGjZpte6VSyTLLLJOqqqrssMMOdbZVVVXlF7/4xZcev2fPnrXHr6qqSseOHbP++uvnyiuvTE1NTb1mfP311/Ozn/0syy+/fFq0aJG2bdtm4403zgUXXJCpU6fW/2TnQ//+/fP888/n1FNPzTXXXJPvfe97C/T9FqYBAwakqqoqbdu2neP38dVXX63993b22WfP8/Hfe++9DBo0KKNHj26AaYH/NYs09gDAN0uLFi0yfPjwbLLJJnXWH3roobz77ruprq6e72MvvfTSGTx4cJJk3Lhxufrqq7Pvvvvmn//8Z04//fQvfe3tt9+e3XbbLdXV1fnJT36S1VdfPTNmzMioUaNy1FFH5cUXX8zvfve7+Z7ty0ydOjWPPvpofvnLX35llM+vrl27ZurUqWnWrNkCOf5XWWSRRTJlypT85S9/Sb9+/eps++Mf/5gWLVpk2rRp83Xs9957LyeddFK6deuWtddeu96vu/vuu+fr/YCyuLIKNKjtttsuN9xwQz777LM668OHD896662XLl26zPex27Vrl7322it77bVXDj/88DzyyCNZeumlc/HFF2fmzJlzfd2bb76ZPfbYI127ds1LL72UCy64IPvvv38OOuigXHvttXnppZey2mqrzfdcX2XcuHFJkvbt2y+w96iqqkqLFi3StGnTBfYeX6a6ujpbbLFFrr322tm2DR8+PNtvv/1Cm2XKlClJkubNm6d58+YL7X2BBUOsAg3qRz/6USZMmJB77rmndm3GjBm58cYbs+eeezboey266KL5wQ9+kMmTJ9cG4ZyceeaZ+fTTT3PFFVdkiSWWmG37iiuumEMPPbT2688++yynnHJKVlhhhVRXV6dbt245/vjjM3369Dqv69atW3bYYYeMGjUq3//+99OiRYssv/zyufrqq2v3GTRoULp27ZokOeqoo1JVVZVu3bol+fzH51/8838aNGhQqqqq6qzdc8892WSTTdK+ffu0bt063bt3z/HHH1+7fW73rN5///3ZdNNN06pVq7Rv3z477bRT/vGPf8zx/V577bUMGDAg7du3T7t27bL33nvXhl997Lnnnrnzzjvz8ccf1649+eSTefXVV+f47/6jjz7KkUcemTXWWCOtW7dO27Zts+222+bZZ5+t3efBBx/M+uuvnyTZe++9a28n+OI8e/bsmdVXXz1PP/10Nttssyy66KK135f/vme1f//+adGixWznv/XWW6dDhw5577336n2uwMIjVoEG1a1bt2y44YZ1rrDdeeed+eSTT7LHHns0+Pu98cYbadq06ZdetfzLX/6S5ZdfPhtttFG9jrnffvvl17/+ddZdd92cd9556dGjRwYPHjzH+V977bXsuuuu2XLLLXPOOeekQ4cOGTBgQF588cUkSd++fXPeeecl+Tzkr7nmmpx//vnzdI4vvvhidthhh0yfPj0nn3xyzjnnnOy444555JFHvvR19957b7beeut8+OGHGTRoUAYOHJi//e1v2XjjjTNmzJjZ9u/Xr18mTZqUwYMHp1+/fhk6dGhOOumkes/Zt2/fVFVV5eabb65dGz58eFZeeeWsu+66s+3/xhtvZMSIEdlhhx1y7rnn5qijjsrzzz+fHj161IbjKquskpNPPjlJ8tOf/jTXXHNNrrnmmmy22Wa1x5kwYUK23XbbrL322jn//PPTq1evOc53wQUXpHPnzunfv39mzZqVJLnsssty991356KLLsqSSy5Z73MFFqIKQAO46qqrKkkqTz75ZOXiiy+utGnTpjJlypRKpVKp7LbbbpVevXpVKpVKpWvXrpXtt9++zmuTVA466KAvPX6PHj0qK6+8cmXcuHGVcePGVf7xj39UDjnkkEqSSp8+feb6uk8++aSSpLLTTjvV6zxGjx5dSVLZb7/96qwfeeSRlSSV+++/v3ata9eulSSVkSNH1q59+OGHlerq6soRRxxRu/bmm29WklTOOuusOsfs379/pWvXrrPNcOKJJ1b+86/n8847r5KkMm7cuLnO/cV7XHXVVbVra6+9dmWxxRarTJgwoXbt2WefrTRp0qTyk5/8ZLb322effeocc5dddql85zvfmet7/ud5tGrVqlKpVCq77rprZYsttqhUKpXKrFmzKl26dKmcdNJJc/weTJs2rTJr1qzZzqO6urpy8skn1649+eSTs53bF3r06FFJUhkyZMgct/Xo0aPO2l//+tdKkspvfvObyhtvvFFp3bp1Zeedd/7KcwQajyurQIPr169fpk6dmttuuy2TJk3Kbbfd1iC3ALz88svp3LlzOnfunFVWWSUXXXRRtt9++1x55ZVzfc3EiROTJG3atKnXe9xxxx1JkoEDB9ZZP+KII5J8/kGt/7Tqqqtm0003rf26c+fO6d69e9544416vV99fHHV+M9//nO9n3zw/vvvZ/To0RkwYEA6duxYu77mmmtmyy23rD3P/3TAAQfU+XrTTTfNhAkTar+H9bHnnnvmwQcfzNixY3P//fdn7Nixc/13X11dnSZNPv/P0KxZszJhwoTaWxz+/ve/1/s9q6urs/fee9dr36222io/+9nPcvLJJ6dv375p0aJFLrvssnq/F7DwiVWgwXXu3Dm9e/fO8OHDc/PNN2fWrFnZddddv/Zxu3XrlnvuuSf33ntvRo0albFjx+a2225Lp06d5vqatm3bJkkmTZpUr/d466230qRJk6y44op11rt06ZL27dvnrbfeqrO+7LLLznaMDh065N///ne93q8+dt9992y88cbZb7/9svjii2ePPfbI9ddf/6Xh+sWc3bt3n23bKquskvHjx2fy5Ml11v/7XDp06JAk83Qu2223Xdq0aZPrrrsuf/zjH7P++uvP9r38Qk1NTc4777x897vfTXV1dTp16pTOnTvnueeeyyeffFLv91xqqaXm6YNUZ599djp27JjRo0fnwgsvzGKLLVbv1wILn0dXAQvEnnvumf333z9jx47Ntttu2yCfhG/VqlV69+49T69p27Ztllxyybzwwgvz9Lr//oDT3Mzt0/eVSmW+3+OL+ym/0LJly4wcOTIPPPBAbr/99tx111257rrrsvnmm+fuu+9usCcAfJ1z+UJ1dXX69u2bYcOG5Y033sigQYPmuu9pp52WE044Ifvss09OOeWUdOzYMU2aNMlhhx1W7yvIyeffn3nxzDPP5MMPP0ySPP/88/nRj340T68HFi5XVoEFYpdddkmTJk3y2GOPNfhTAObVDjvskNdffz2PPvroV+7btWvX1NTU5NVXX62z/sEHH+Tjjz+u/WR/Q+jQoUOdT85/4b+v3iZJkyZNssUWW+Tcc8/NSy+9lFNPPTX3339/HnjggTke+4s5X3nlldm2vfzyy+nUqVNatWr19U5gLvbcc88888wzmTRp0pd+qO7GG29Mr169csUVV2SPPfbIVlttld69e8/2Panv/zjUx+TJk7P33ntn1VVXzU9/+tOceeaZefLJJxvs+EDDE6vAAtG6detceumlGTRoUPr06dOosxx99NFp1apV9ttvv3zwwQezbX/99ddzwQUXJPn8x9hJZvvE/rnnnpskDfq80BVWWCGffPJJnnvuudq1999/P7fcckud/T766KPZXvvFw/H/+3FaX1hiiSWy9tprZ9iwYXXi74UXXsjdd99de54LQq9evXLKKafk4osv/tLn6jZt2nS2q7Y33HBD/vWvf9VZ+yKq5xT28+qYY47J22+/nWHDhuXcc89Nt27d0r9//7l+H4HG5zYAYIHp379/vfd96qmn8pvf/Ga29Z49e87227Dm1QorrJDhw4dn9913zyqrrFLnN1j97W9/yw033JABAwYkSdZaa630798/v/vd7/Lxxx+nR48eeeKJJzJs2LDsvPPOc30s0vzYY489cswxx2SXXXbJIYcckilTpuTSSy/NSiutVOcDRieffHJGjhyZ7bffPl27ds2HH36Y3/72t1l66aW/9Htz1llnZdttt82GG26YfffdN1OnTs1FF12Udu3afemP57+uJk2a5Fe/+tVX7rfDDjvk5JNPzt57752NNtoozz//fP74xz9m+eWXr7PfCiuskPbt22fIkCFp06ZNWrVqlQ022CDLLbfcPM11//3357e//W1OPPHE2kdpXXXVVenZs2dOOOGEnHnmmfN0PGDhEKtAER5//PE8/vjjs62fcsopXztWk2THHXfMc889l7POOit//vOfc+mll6a6ujprrrlmzjnnnOy///61+15++eVZfvnlM3To0Nxyyy3p0qVLjjvuuJx44olfe47/9J3vfCe33HJLBg4cmKOPPjrLLbdcBg8enFdffbVOrO64444ZM2ZMrrzyyowfPz6dOnVKjx49ctJJJ6Vdu3ZzPX7v3r1z11135cQTT8yvf/3rNGvWLD169MgZZ5wxz6G3IBx//PGZPHlyhg8fnuuuuy7rrrtubr/99hx77LF19mvWrFmGDRuW4447LgcccEA+++yzXHXVVfN0DpMmTco+++yTddZZJ7/85S9r1zfddNMceuihOeecc9K3b9/84Ac/aLDzAxpGVWVe7pwHAICFyD2rAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLG+kb8UoGrLpRt7BIAGNfGOFxp7BIAG1aZZ+3rt58oqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFWqSxB4CSHLvHQem7ybZZeZkVM3X6tPztpadyzOWn5Z/vvlG7z+IdOuesn/4qW667adq0bJ1X3n09pw6/KDePuqN2n3VWXD1n7Hd81u++VmbV1OSmh+/IwCEnZfK0KY1xWgB19Nlq57z/3vuzre+2xw9zzK+Ozs033JK7br87r/zj5UyePCUP/O3etGnbphEmBVdWoY4ea26YS24dlh8csmO2PPZHabZIs9x9+vAs2qJl7T5XH3N+ui+9Qnb89T5Z46e9c/OoO3P9ry7N2iusliRZ4juL594z/pTX3huTDQ7uk22O2yurdVspQ486r7FOC6COq/90Ve568I7aP5f8/qIkyRZbbZEkmTZtWjba5AfZe/8BjTglfM6VVfgP2x6/V52vB5x1eMbd+FzW++6aefj5x5MkG636vRx44fF58pXRSZJTh1+Yw3+4f9Zbac2Mfv3F7LBB78ycNTMHXfTLVCqVJMkB5x+X539/b1ZYsltef2/MwjwlgNl06NihztfDLh+WpZdZOuutv26SZM//+1GS5Kknnl7os8F/a9RYHT9+fK688so8+uijGTt2bJKkS5cu2WijjTJgwIB07ty5MceDtGvVNkny0aSPa9f+9tJT2b1Hn9z++H35+NNP0q9Hn7RoVp0Hn300SVLdrHlmzJxZG6pJMnXGtCTJJquvL1aBosycOTN33HZXfvyTPVNVVdXY48BsGu02gCeffDIrrbRSLrzwwrRr1y6bbbZZNttss7Rr1y4XXnhhVl555Tz11FNfeZzp06dn4sSJdf6kpvKVr4OvUlVVlfMPHJRRLzyRF8e8Urve75QD02yRRfLRzS9k+h1v5LLDTs8uJ+1XG6H3j34kXTp2zpG7HZBmizRL+9btcvq+xyVJlui4WGOcCsBcPXjfQ/l00qfps/P2jT0KzFGjXVk9+OCDs9tuu2XIkCGz/Z9cpVLJAQcckIMPPjiPPvrolx5n8ODBOemkk+ouLtcmWaFtQ4/Mt8wlB5+a1bt1zyaH962zfsqAo9K+VbtscfTuGf/JR9l5o21y/a8uzaaH/zAvjHk5L731z/Q/8/Cce8CvM3jfYzNr1qxcOOKqjP3ow9RU/I8UUJY/33xrNtpkw3RezE8zKVNVpdI4//Vs2bJlnnnmmay88spz3P7yyy9nnXXWydSpU7/0ONOnT8/06dPrrLXbZZWkiR9lMP8u+sVvstOGW2WzI36YMWPfqV1ffomuef3qR7Lafpvnpbf+Wbt+zxnX5rX3xuTAC46rc5zF2nfK5GlTUkklE0e8nD1O+3luHHn7QjsPvjkm3vFCY4/AN9D7772fnbbpmzPPPz09N+8x2/annng6B+zzc08DYIFo06x9vfZrtCurXbp0yRNPPDHXWH3iiSey+OKLf+VxqqurU11dXXdRqPI1XPSL32SXjbdJzyN3qxOqSbJo9edPBaip1NRZn1UzK02qZr+r5sOPxydJ9t5690ybMT33PP3wApoaYN7destt6dCxQzbZbOPGHgXmqtFi9cgjj8xPf/rTPP3009liiy1qw/SDDz7Ifffdl9///vc5++yzG2s8vqUuOfjU7Ln5ztnpxH0zacqnWbzD5z8W+2TypEybMS0vv/NaXv3Xm7ns0NNz5O9+kwkT/52dN946W667WXY4YUDtcQ7aaUD+9uJT+XTq5Gy53mY5a/9f5dgrBueTyRMb6cwA6qqpqclfRtyWHXbaPossUjcHxo+fkAnjJ+Tdt99Nkrz26mtZtFWrdFli8bRr164xxuVbrNFuA0iS6667Luedd16efvrpzJo1K0nStGnTrLfeehk4cGD69es3X8et2nLphhyTb5HKPe/OcX3AWYdn2N03JElWXGq5nL7vcdlk9fXTukWrvPbemJx942X5w7031e4/7Ojzs/0GW6R1i0Xz8juvz7Yd5pXbAGhojz3yWH7xs0Nz0203pGu3Zetsu+yS3+f3l14+22tO/M0J6bPzDgtrRL7h6nsbQKPG6hdmzpyZ8eM//3Fpp06d0qxZs691PLEKfNOIVeCbpvh7Vv9Ts2bNssQSSzT2GAAAFMavWwUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYolVAACKJVYBACiWWAUAoFhiFQCAYi1Sn51uvfXWeh9wxx13nO9hAADgP9UrVnfeeed6HayqqiqzZs36OvMAAECtesVqTU3Ngp4DAABm455VAACKVa8rq/9t8uTJeeihh/L2229nxowZdbYdcsghDTIYAADMc6w+88wz2W677TJlypRMnjw5HTt2zPjx47PoootmscUWE6sAADSYeb4N4PDDD0+fPn3y73//Oy1btsxjjz2Wt956K+utt17OPvvsBTEjAADfUvMcq6NHj84RRxyRJk2apGnTppk+fXqWWWaZnHnmmTn++OMXxIwAAHxLzXOsNmvWLE2afP6yxRZbLG+//XaSpF27dnnnnXcadjoAAL7V5vme1XXWWSdPPvlkvvvd76ZHjx759a9/nfHjx+eaa67J6quvviBmBADgW2qer6yedtppWWKJJZIkp556ajp06JADDzww48aNy+9+97sGHxAAgG+vqkqlUmnsIRpa1ZZLN/YIAA1q4h0vNPYIAA2qTbP29drPLwUAAKBY83zP6nLLLZeqqqq5bn/jjTe+1kAAAPCFeY7Vww47rM7XM2fOzDPPPJO77rorRx11VEPNBQAA8x6rhx566BzXL7nkkjz11FNfeyAAAPhCg92zuu222+amm25qqMMBAEDDxeqNN96Yjh07NtThAABg/n4pwH9+wKpSqWTs2LEZN25cfvvb3zbocAAAfLvNc6zutNNOdWK1SZMm6dy5c3r27JmVV165QYebX1Pv+mdjjwDQoFY6c/vGHgGgQb193AP12m+eY3XQoEHz+hIAAJgv83zPatOmTfPhhx/Otj5hwoQ0bdq0QYYCAIBkPmJ1br+ddfr06WnevPnXHggAAL5Q79sALrzwwiRJVVVVLr/88rRu3bp226xZszJy5Mhi7lkFAOCbod6xet555yX5/MrqkCFD6vzIv3nz5unWrVuGDBnS8BMCAPCtVe9YffPNN5MkvXr1ys0335wOHTossKEAACCZj6cBPPBA/R4zAAAAX9c8f8Dqhz/8Yc4444zZ1s8888zstttuDTIUAAAk8xGrI0eOzHbbbTfb+rbbbpuRI0c2yFAAAJDMR6x++umnc3xEVbNmzTJx4sQGGQoAAJL5iNU11lgj11133Wzrf/rTn7Lqqqs2yFAAAJDMxwesTjjhhPTt2zevv/56Nt988yTJfffdl+HDh+fGG29s8AEBAPj2mudY7dOnT0aMGJHTTjstN954Y1q2bJm11lor999/fzp27LggZgQA4FuqqjK3359aTxMnTsy1116bK664Ik8//XRmzZrVULPNt2mzpjT2CAANaqUzt2/sEQAa1NvH1e9xqPN8z+oXRo4cmf79+2fJJZfMOeeck8033zyPPfbY/B4OAABmM0+3AYwdOzZDhw7NFVdckYkTJ6Zfv36ZPn16RowY4cNVAAA0uHpfWe3Tp0+6d++e5557Lueff37ee++9XHTRRQtyNgAAvuXqfWX1zjvvzCGHHJIDDzww3/3udxfkTAAAkGQerqyOGjUqkyZNynrrrZcNNtggF198ccaPH78gZwMA4Fuu3rH6gx/8IL///e/z/vvv52c/+1n+9Kc/Zckll0xNTU3uueeeTJo0aUHOCQDAt9A8Pw2gVatW2WeffTJq1Kg8//zzOeKII3L66adnscUWy4477rggZgQA4Ftqvh9dlSTdu3fPmWeemXfffTfXXnttQ80EAABJGuCXApTILwUAvmn8UgDgm2aB/1IAAABY0MQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFWqSxB4DSffDBhzn/nAvyyMOPZNq0aVlm2WVy8qmDstrqqyVJLr14SO66868ZO3ZsmjVrllVXXSW/OPQXWXOtNRp5coDkoA33zDbdN80KHZfNtM+m5+l/vZjBD/wub3z0Tu0+g7cZmE26rZvFW3fK5JlT8/S7L2bwA5fl9f9vn13X2Drn7nDsHI+/zgW7ZMKUjxfGqfAtVVWpVCqNPURDmzZrSmOPwDfExE8mZvcf7pHvfX/99Ntjt3To2CFvv/V2lllm6Syz7DJJkjtuuzMdO3bI0sssnWnTpucPV/8h9/z13vzlrj+nY8eOjXwGfFOsdOb2jT0C/6Ou3v2M3PrS/Xnu/VfStEnTHN1jv3Tv3C1b/H7vTJ05LUmy59o75LUJb+e9iR+kfYu2OXzT/ll1sRWz8aV7pqZSk+pFmqdtdas6xz1nh2NT3bR5dh9+eGOcFt8Abx/3QL32E6vwJc4/94KM/vuzGfqHK+v9mk8//TQbf3/T/O6KIdlgww0W4HR8m4hVGkrHlu0y+rAR2fUPh+aJd56b4z4rd14+d+93RTa99Md56+P35niMJw6+IUffcVZufuGeBT0y31D1jVX3rMKXeOj+h7La6qvmyMOOSs9NNk+/vnvkphtunuv+M2fMzE3X35w2bVpnpZVXWoiTAtRPmxafXyH9eOrEOW5v2axF+q25Td7+93t5b+KHc9znh2tslakzp+f2lx9aYHPCF4q+Z/Wdd97JiSeemCuvnPtVrenTp2f69Ol11iqLzEp1dfWCHo9vgXff/Veu/9MN+b/+e2Xfn+6bF194MWecdmaaNVskO+68Y+1+Dz04MscccWymTZuWTp07ZcjlQ9KhQ4dGnBxgdlWpyqDev8iT7zyff44fU2fb/627U47v9bO0at4yr014Oz/+01GZWfPZHI+zx1rb5c8v3Zfpn81YCFPzbVf0ldWPPvoow4YN+9J9Bg8enHbt2tX5c9bpZy+kCfmmq6mpySqrrpxDDj84q6y6cnbt98P03XWX3HDdjXX2W//76+f6m/+Uq4cPzcabbJSjBh6dCRM+aqSpAebsN1sfmpU6LZeD/nzybNtGvHhvtr1y/+z6h0Pz5kfv5Lc7n5jqps1m22/dpVbNdzt1y3XP3rEwRobGvbJ66623fun2N9544yuPcdxxx2XgwIF11iqLzPpac8EXOnfulOVXWL7O2vIrLJd777mvztqii7bMsl2XzbJdl82aa62ZPtvsmBE33ZJ9f7rvwhwXYK5O3uqQbLHihtntD4dm7KTxs22fNH1yJk2fnDH//lee+ddLef7wW7N1901z60v319lvj7W2zwtjX83zY/+5sEbnW65RY3XnnXdOVVVVvuwzXlVVVV96jOrq6tl+5O8DVjSUtdddO2PefKvO2ltj3s6SSy7xpa+rqVQyY8bMBTkaQL2dvNUh2WalTdLvj4fnnU/GfuX+VVVVqaqqSvP/urK6aLMW2WHlnjnjod8vqFFhNo16G8ASSyyRm2++OTU1NXP88/e//70xx4Ps9ZO98vxzz+fyy67I22+9nTtuuzM33nBTdv/R7kmSKVOm5sLzLspzzz6X9/71Xl568aX8+peD8uEHH2bLrbds5OkBkt9sfVh2WW3LHPznUzN5xpR0btUhnVt1SPUizZMky7ZfIgdtuGfW6LJSlmy7WNZbarVcusuJmfbZ9Dzw+uN1jtVnlc2zSJOmucUTAFiIGvXK6nrrrZenn346O+200xy3f9VVV1jQVl9jtZx74Tm58LyLctmlv8tSSy+Vo489Ktv32S5J0rRpk7z55pjceuhf8vG/P0779u2y2uqr5aprrsyK312hkacHSH6y7uf/jb1hr/PrrA+87fTc+PxfM/2zGVl/mTWyz/o/TLsWbTJ+8r/z+DvPZZerD57tYf+7r7Vt7vznw5k4ffJCmh4a+TmrDz/8cCZPnpxtttlmjtsnT56cp556Kj169Jin47oNAPim8ZxV4Jumvs9ZbdQrq5tuuumXbm/VqtU8hyoAAN8cRT+6CgCAbzexCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUKyqSqVSaewh4H/R9OnTM3jw4Bx33HGprq5u7HEAvjZ/r1EisQrzaeLEiWnXrl0++eSTtG3btrHHAfja/L1GidwGAABAscQqAADFEqsAABRLrMJ8qq6uzoknnuhDCMA3hr/XKJEPWAEAUCxXVgEAKJZYBQCgWGIVAIBiiVUAAIolVmE+XXLJJenWrVtatGiRDTbYIE888URjjwQwX0aOHJk+ffpkySWXTFVVVUaMGNHYI0EtsQrz4brrrsvAgQNz4okn5u9//3vWWmutbL311vnwww8bezSAeTZ58uSstdZaueSSSxp7FJiNR1fBfNhggw2y/vrr5+KLL06S1NTUZJlllsnBBx+cY489tpGnA5h/VVVVueWWW7Lzzjs39iiQxJVVmGczZszI008/nd69e9euNWnSJL17986jjz7aiJMBwDePWIV5NH78+MyaNSuLL754nfXFF188Y8eObaSpAOCbSawCAFAssQrzqFOnTmnatGk++OCDOusffPBBunTp0khTAcA3k1iFedS8efOst956ue+++2rXampqct9992XDDTdsxMkA4JtnkcYeAP4XDRw4MP3798/3vve9fP/738/555+fyZMnZ++9927s0QDm2aeffprXXnut9us333wzo0ePTseOHbPssss24mTg0VUw3y6++OKcddZZGTt2bNZee+1ceOGF2WCDDRp7LIB59uCDD6ZXr16zrffv3z9Dhw5d+APBfxCrAAAUyz2rAAAUS6wCAFAssQoAQLHEKgAAxRKrAAAUS6wCAFAssQoAQLHEKgAAxRKrAIUZMGBAdt5559qve/bsmcMOO2yhz/Hggw+mqqoqH3/88UJ/b4AviFWAehowYECqqqpSVVWV5s2bZ8UVV8zJJ5+czz77bIG+780335xTTjmlXvsKTOCbZpHGHgDgf8k222yTq666KtOnT88dd9yRgw46KM2aNctxxx1XZ78ZM2akefPmDfKeHTt2bJDjAPwvcmUVYB5UV1enS5cu6dq1aw488MD07t07t956a+2P7k899dQsueSS6d69e5LknXfeSb9+/dK+fft07NgxO+20U8aMGVN7vFmzZmXgwIFp3759vvOd7+Too49OpVKp857/fRvA9OnTc8wxx2SZZZZJdXV1VlxxxVxxxRUZM2ZMevXqlSTp0KFDqqqqMmDAgCRJTU1NBg8enOWWWy4tW7bMWmutlRtvvLHO+9xxxx1ZaaWV0rJly/Tq1avOnACNRawCfA0tW7bMjBkzkiT33XdfXnnlldxzzz257bbbMnPmzGy99dZp06ZNHn744TzyyCNp3bp1ttlmm9rXnHPOORk6dGiuvPLKjBo1Kh999FFuueWWL33Pn/zkJ7n22mtz4YUX5h//+Ecuu+yytG7dOssss0xuuummJMkrr7yS999/PxdccEGSZPDgwbn66qszZMiQvPjiizn88MOz11575aGHHkryeVT37ds3ffr0yejRo7Pffvvl2GOPXVDfNoB6cxsAwHyoVCq577778te//jUHH3xwxo0bl1atWuXyyy+v/fH/H/7wh9TU1OTyyy9PVVVVkuSqq65K+/bt8+CDD2arrbbK+eefn+OOOy59+/ZNkgwZMiR//etf5/q+//znP3P99dfnnnvuSe/evZMkyy+/fO32L24ZWGyxxdK+ffskn1+JPe2003Lvvfdmww03rH3NqFGjctlll6VHjx659NJLs8IKK+Scc85JknTv3j3PP/98zjjjjAb8rgHMO7EKMA9uu+22tG7dOjNnzkxNTU323HPPDBo0KAcddFDWWGONOvepPvvss3nttdfSpk2bOseYNm1aXn/99XzyySd5//33s8EGG9RuW2SRRfK9731vtlsBvjB69Og0bdo0PXr0qPfMr732WqZMmZItt9yyzvqMGTOyzjrrJEn+8Y9/1JkjSW3YAjQmsQowD3r16pVLL700zZs3z5JLLplFFvn//xpt1apVnX0//fTTrLfeevnjH/8423E6d+48X+/fsmXLeX7Np59+miS5/fbbs9RSS9XZVl1dPV9zACwsYhVgHrRq1SorrrhivfZdd911c91112WxxRZL27Zt57jPEksskccffzybbbZZkuSzzz7L008/nXXXXXeO+6+xxhqpqanJQw89VHsbwH/64srurFmzatdWXXXVVFdX5+23357rFdlVVlklt956a521xx577KtPEmAB8wErgAXkxz/+cTp16pSddtopDz/8cN588808+OCDOeSQQ/Luu+8mSQ499NCcfvrpGTFiRF5++eX8/Oc//9JnpHbr1i39+/fPPvvskxEjRtQe8/rrr0+SdO3aNVVVVbntttsybty4fPrpp2nTpk2OPPLIHH744Rk2bFhef/31/P3vf89FF12UYcOGJUkOOOCAvPrqqznqqKPyyiuvZPjw4Rk6dOiC/hYBfCWxCrCALLroohk5cmSWXXbZ9O3bN6usskr23XffTJs2rfZK6xFHHJH/+7//S//+/bPhhhumTZs22WWXXb70uJdeeml23XXX/PznP8/KK6+c/fffP5MnT06SLLXUUjnppJNy7LHHZvHFF88vfvGLJMkpp5ySE044IYMHD84qq6ySbbbZJrfffnuWW265JMmyyy6bm266KSNGjMhaa62VIUOG5LTTTluA3x2A+qmqzO0ufgAAaGSurAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADFEqsAABRLrAIAUCyxCgBAscQqAADF+n9yuXod8uxj7AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SVM Model with Grid Search\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}\n",
    "svm_grid = GridSearchCV(SVC(random_state=42), svm_param_grid, cv=5, n_jobs=-1)\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"SVM Best Parameters:\", svm_grid.best_params_)\n",
    "print(\"SVM Best Score:\", svm_grid.best_score_)\n",
    "\n",
    "# Predictions and evaluation for SVM\n",
    "svm_pred = svm_grid.predict(X_test_scaled)\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_pred))\n",
    "\n",
    "# Plot SVM Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "svm_cm = confusion_matrix(y_test, svm_pred)\n",
    "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"SVM Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# MLP Model with Grid Search\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "mlp_grid = GridSearchCV(MLPClassifier(random_state=42, max_iter=1000), mlp_param_grid, cv=5, n_jobs=-1)\n",
    "mlp_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nMLP Best Parameters:\", mlp_grid.best_params_)\n",
    "print(\"MLP Best Score:\", mlp_grid.best_score_)\n",
    "\n",
    "# Predictions and evaluation for MLP\n",
    "mlp_pred = mlp_grid.predict(X_test_scaled)\n",
    "print(\"\\nMLP Classification Report:\")\n",
    "print(classification_report(y_test, mlp_pred))\n",
    "\n",
    "# Plot MLP Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "mlp_cm = confusion_matrix(y_test, mlp_pred)\n",
    "sns.heatmap(mlp_cm, annot=True, fmt='d', cmap='Greens', cbar=False)\n",
    "plt.title(\"MLP Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
