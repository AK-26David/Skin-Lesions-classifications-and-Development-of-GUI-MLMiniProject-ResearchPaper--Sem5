{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Features ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(image):\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute the GLCM (Gray Level Co-occurrence Matrix)\n",
    "    glcm = greycomatrix(gray_image, distances=[1], angles=[0], symmetric=True, normed=True)\n",
    "    \n",
    "    # Extract texture properties: Contrast, Correlation, Energy, and Homogeneity\n",
    "    contrast = greycoprops(glcm, 'contrast')[0, 0]\n",
    "    correlation = greycoprops(glcm, 'correlation')[0, 0]\n",
    "    energy = greycoprops(glcm, 'energy')[0, 0]\n",
    "    homogeneity = greycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    \n",
    "    return [contrast, correlation, energy, homogeneity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image):\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute HOG features\n",
    "    hog_features, hog_image = hog(gray_image, \n",
    "                                  pixels_per_cell=(16, 16), \n",
    "                                  cells_per_block=(2, 2), \n",
    "                                  block_norm='L2-Hys', \n",
    "                                  visualize=True, \n",
    "                                  multichannel=False)\n",
    "    \n",
    "    return hog_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Loop through subfolders, where each folder represents a class (e.g., Benign or Malignant)\n",
    "    for label_folder in os.listdir(folder):\n",
    "        label_path = os.path.join(folder, label_folder)\n",
    "        if os.path.isdir(label_path):\n",
    "            for filename in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, filename)\n",
    "                img = cv2.imread(img_path)  # Read the image\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(label_folder)  # The folder name becomes the class label\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_images):\n",
    "    X_features = []\n",
    "    \n",
    "    for img in X_images:\n",
    "        # Extract GLCM (texture) features\n",
    "        glcm_features = extract_glcm_features(img)\n",
    "        \n",
    "        # Extract HOG (shape) features\n",
    "        hog_features = extract_hog_features(img)\n",
    "        \n",
    "        # Combine both sets of features\n",
    "        combined_features = np.concatenate((glcm_features, hog_features))\n",
    "        \n",
    "        # Add the combined features to the feature list\n",
    "        X_features.append(combined_features)\n",
    "        \n",
    "    return np.array(X_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X_features \u001b[38;5;241m=\u001b[39m prepare_data(X_images)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Split dataset into training and test sets (80% train, 20% test)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Scale the feature data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "File \u001b[0;32m~/Documents/Skin-Lesions-classifications-and-Development-of-GUI/.venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Skin-Lesions-classifications-and-Development-of-GUI/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2785\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Skin-Lesions-classifications-and-Development-of-GUI/.venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2415\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2412\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2419\u001b[0m     )\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Load dataset (assuming images are stored in 'data' folder)\n",
    "X_images, y_labels = load_images_from_folder('ISIC-images')\n",
    "\n",
    "# Prepare feature set by extracting features from the images\n",
    "X_features = prepare_data(X_images)\n",
    "\n",
    "# Split dataset into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@400.466] global loadsave.cpp:241 findDecoder imread_('path_to_your_image.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 116\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m    115\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_your_image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 116\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_lesion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features from the image.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 104\u001b[0m, in \u001b[0;36manalyze_lesion\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_lesion\u001b[39m(image_path):\n\u001b[0;32m--> 104\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     color_features \u001b[38;5;241m=\u001b[39m extract_color_features(img)\n\u001b[1;32m    107\u001b[0m     texture_features \u001b[38;5;241m=\u001b[39m extract_texture_features(img)\n",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path, target_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m300\u001b[39m)):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m---> 10\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Resize\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, target_size)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy.stats import skew\n",
    "\n",
    "def preprocess_image(image_path, target_size=(300, 300)):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Extract the circular region of interest\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, (img.shape[1]//2, img.shape[0]//2), min(img.shape[0], img.shape[1])//2 - 10, (255), -1)\n",
    "    img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    enhanced_lab = cv2.merge((cl,a,b))\n",
    "    img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    # Normalize\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "def extract_color_features(img):\n",
    "    features = []\n",
    "    \n",
    "    # Color moments (mean, std, skewness) for each channel\n",
    "    for i in range(3):\n",
    "        channel = img[:,:,i]\n",
    "        features.extend([channel[channel != 0].mean(), channel[channel != 0].std(), skew(channel[channel != 0].ravel())])\n",
    "    \n",
    "    # Color histograms\n",
    "    for i in range(3):\n",
    "        hist = cv2.calcHist([img], [i], None, [32], [0, 1])\n",
    "        features.extend(hist.flatten())\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_texture_features(img):\n",
    "    features = []\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Local Binary Patterns\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    features.extend(hist)\n",
    "    \n",
    "    # Haralick texture features\n",
    "    glcm = graycomatrix(gray, [5], [0], 256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "    for prop in props:\n",
    "        features.extend(graycoprops(glcm, prop).flatten())\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_shape_features(img):\n",
    "    features = []\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Area and Perimeter\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        features.extend([area, perimeter])\n",
    "        \n",
    "        # Circularity\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "        features.append(circularity)\n",
    "        \n",
    "        # Asymmetry\n",
    "        (x, y), (MA, ma), angle = cv2.fitEllipse(cnt)\n",
    "        asymmetry = MA / ma\n",
    "        features.append(asymmetry)\n",
    "        \n",
    "        # Border irregularity\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = float(area) / hull_area\n",
    "        features.append(solidity)\n",
    "    else:\n",
    "        features.extend([0] * 5)  # Placeholder if no contour found\n",
    "    \n",
    "    return features\n",
    "\n",
    "def analyze_lesion(image_path):\n",
    "    img = preprocess_image(image_path)\n",
    "    \n",
    "    color_features = extract_color_features(img)\n",
    "    texture_features = extract_texture_features(img)\n",
    "    shape_features = extract_shape_features(img)\n",
    "    \n",
    "    all_features = np.concatenate([color_features, texture_features, shape_features])\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "# Usage\n",
    "image_path = \"path_to_your_image.jpg\"\n",
    "features = analyze_lesion(image_path)\n",
    "print(f\"Extracted {len(features)} features from the image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 100/100 [00:04<00:00, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 images. Results saved to 'skin_lesion_features.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy.stats import skew\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_image(img, target_size=(300, 300)):\n",
    "    # Resize\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Extract the circular region of interest\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, (img.shape[1]//2, img.shape[0]//2), min(img.shape[0], img.shape[1])//2 - 10, (255), -1)\n",
    "    img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    enhanced_lab = cv2.merge((cl,a,b))\n",
    "    img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    # Normalize\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "def extract_color_features(img):\n",
    "    features = []\n",
    "    \n",
    "    # Color moments (mean, std, skewness) for each channel\n",
    "    for i in range(3):\n",
    "        channel = img[:,:,i]\n",
    "        features.extend([channel[channel != 0].mean(), channel[channel != 0].std(), skew(channel[channel != 0].ravel())])\n",
    "    \n",
    "    # Color histograms\n",
    "    for i in range(3):\n",
    "        hist = cv2.calcHist([img], [i], None, [32], [0, 1])\n",
    "        features.extend(hist.flatten())\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_texture_features(img):\n",
    "    features = []\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Local Binary Patterns\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    features.extend(hist)\n",
    "    \n",
    "    # Haralick texture features\n",
    "    glcm = graycomatrix(gray, [5], [0], 256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "    for prop in props:\n",
    "        features.extend(graycoprops(glcm, prop).flatten())\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_shape_features(img):\n",
    "    features = []\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Area and Perimeter\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        features.extend([area, perimeter])\n",
    "        \n",
    "        # Circularity\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "        features.append(circularity)\n",
    "        \n",
    "        # Asymmetry\n",
    "        (x, y), (MA, ma), angle = cv2.fitEllipse(cnt)\n",
    "        asymmetry = MA / ma\n",
    "        features.append(asymmetry)\n",
    "        \n",
    "        # Border irregularity\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = float(area) / hull_area\n",
    "        features.append(solidity)\n",
    "    else:\n",
    "        features.extend([0] * 5)  # Placeholder if no contour found\n",
    "    \n",
    "    return features\n",
    "\n",
    "def analyze_lesion(img):\n",
    "    img = preprocess_image(img)\n",
    "    \n",
    "    color_features = extract_color_features(img)\n",
    "    texture_features = extract_texture_features(img)\n",
    "    shape_features = extract_shape_features(img)\n",
    "    \n",
    "    all_features = np.concatenate([color_features, texture_features, shape_features])\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "def process_image_folder(folder_path):\n",
    "    all_features = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        features = analyze_lesion(img)\n",
    "        all_features.append(features)\n",
    "        image_names.append(image_file)\n",
    "    \n",
    "    # Create a DataFrame with the features\n",
    "    feature_names = [f'feature_{i}' for i in range(len(all_features[0]))]\n",
    "    df = pd.DataFrame(all_features, columns=feature_names)\n",
    "    df['image_name'] = image_names\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "folder_path = \"/Users/arnavkarnik/Documents/Skin-Lesions-classifications-and-Development-of-GUI/ISIC-images\"\n",
    "results_df = process_image_folder(folder_path)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(\"skin_lesion_features.csv\", index=False)\n",
    "print(f\"Processed {len(results_df)} images. Results saved to 'skin_lesion_features.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 100/100 [00:04<00:00, 22.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 images. Results saved to 'skin_lesion_features.csv'\n",
      "Total number of features: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy.stats import skew\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_image(img, target_size=(300, 300)):\n",
    "    # Resize\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Extract the circular region of interest\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, (img.shape[1]//2, img.shape[0]//2), min(img.shape[0], img.shape[1])//2 - 10, (255), -1)\n",
    "    img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Enhance contrast\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    enhanced_lab = cv2.merge((cl,a,b))\n",
    "    img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    # Normalize\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "def extract_color_features(img):\n",
    "    features = {}\n",
    "    channels = ['R', 'G', 'B']\n",
    "    \n",
    "    # Color moments (mean, std, skewness) for each channel\n",
    "    for i, channel in enumerate(channels):\n",
    "        channel_data = img[:,:,i]\n",
    "        features[f'color_mean_{channel}'] = channel_data[channel_data != 0].mean()\n",
    "        features[f'color_std_{channel}'] = channel_data[channel_data != 0].std()\n",
    "        features[f'color_skew_{channel}'] = skew(channel_data[channel_data != 0].ravel())\n",
    "    \n",
    "    # Color histograms\n",
    "    for i, channel in enumerate(channels):\n",
    "        hist = cv2.calcHist([img], [i], None, [32], [0, 1])\n",
    "        for j, value in enumerate(hist.flatten()):\n",
    "            features[f'color_hist_{channel}_{j}'] = value\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_texture_features(img):\n",
    "    features = {}\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Local Binary Patterns\n",
    "    radius = 3\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    for i, value in enumerate(hist):\n",
    "        features[f'lbp_{i}'] = value\n",
    "    \n",
    "    # Haralick texture features\n",
    "    glcm = graycomatrix(gray, [5], [0], 256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "    for prop in props:\n",
    "        value = graycoprops(glcm, prop)[0, 0]\n",
    "        features[f'haralick_{prop}'] = value\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_shape_features(img):\n",
    "    features = {}\n",
    "    \n",
    "    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Area and Perimeter\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        features['shape_area'] = area\n",
    "        features['shape_perimeter'] = perimeter\n",
    "        \n",
    "        # Circularity\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "        features['shape_circularity'] = circularity\n",
    "        \n",
    "        # Asymmetry\n",
    "        (x, y), (MA, ma), angle = cv2.fitEllipse(cnt)\n",
    "        asymmetry = MA / ma\n",
    "        features['shape_asymmetry'] = asymmetry\n",
    "        \n",
    "        # Border irregularity\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = float(area) / hull_area\n",
    "        features['shape_border_irregularity'] = solidity\n",
    "    else:\n",
    "        for feature in ['shape_area', 'shape_perimeter', 'shape_circularity', 'shape_asymmetry', 'shape_border_irregularity']:\n",
    "            features[feature] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "def analyze_lesion(img):\n",
    "    img = preprocess_image(img)\n",
    "    \n",
    "    features = {}\n",
    "    features.update(extract_color_features(img))\n",
    "    features.update(extract_texture_features(img))\n",
    "    features.update(extract_shape_features(img))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def process_image_folder(folder_path):\n",
    "    all_features = []\n",
    "    image_names = []\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        features = analyze_lesion(img)\n",
    "        all_features.append(features)\n",
    "        image_names.append(image_file)\n",
    "    \n",
    "    # Create a DataFrame with the features\n",
    "    df = pd.DataFrame(all_features)\n",
    "    df['image_name'] = image_names\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "folder_path = \"/Users/arnavkarnik/Documents/Skin-Lesions-classifications-and-Development-of-GUI/ISIC-images\"\n",
    "results_df = process_image_folder(folder_path)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(\"skin_lesion_features.csv\", index=False)\n",
    "print(f\"Processed {len(results_df)} images. Results saved to 'skin_lesion_features.csv'\")\n",
    "print(f\"Total number of features: {len(results_df.columns) - 1}\")  # -1 for the image_name column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
